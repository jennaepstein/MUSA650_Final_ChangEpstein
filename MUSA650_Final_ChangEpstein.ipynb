{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radiant_mlhub import Dataset, Collection, client, get_session\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL as pil\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main dataset\n",
    "dataset_df = pd.read_json(\"dataset_df.json\")\n",
    "\n",
    "# View first five rows\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe containing the keys\n",
    "key_df = pd.read_json(\"key_df.json\")\n",
    "\n",
    "# View first five rows\n",
    "key_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output path where the data is located and version of the path as a string\n",
    "output_path = Path(\"./data/\").resolve()\n",
    "output_path_str = str(Path(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to the data on local system\n",
    "data_root=f\"{output_path}/Images\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classes from the Images folder\n",
    "selectedClasses = (os.listdir(data_root))\n",
    "print (selectedClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images are in the dataset\n",
    "print(\"Total images in the dataset: \", len(dataset_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image counts per category, just for reference\n",
    "ac_count = dataset_df['label'].value_counts()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=ac_count.index, y=ac_count.values)\n",
    "plt.title(\"Images count for each label category\", fontsize=16)\n",
    "plt.xlabel(\"Label\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf #deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some sample images before any data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = str(data_root) # data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_plot = ImageDataGenerator()\n",
    "generator_plot = datagen_plot.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(224, 224), #image size (resized for better visualisation clarity)\n",
    "    shuffle = True, #randomize\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting images with labels\n",
    "def plots(ims, figsize = (10,10), rows=4, interp=False, titles=None, maxNum = 10):\n",
    "    if type(ims[0] is np.ndarray):\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if(ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "           \n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = maxNum // rows if maxNum % 2 == 0 else maxNum//rows + 1\n",
    "    for i in range(maxNum):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=12)\n",
    "        plt.imshow(ims[i], interpolation = None if interp else 'none')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_plot.reset()\n",
    "imgs, labels = generator_plot.next() # images to plot\n",
    "\n",
    "# including labels\n",
    "labelNames=[]\n",
    "labelIndices=[np.where(r==1)[0][0] for r in labels]\n",
    "\n",
    "for ind in labelIndices:\n",
    "    for labelName,labelIndex in generator_plot.class_indices.items():\n",
    "        if labelIndex == ind:\n",
    "            labelNames.append(labelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(imgs, rows=1, titles = labelNames, maxNum=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images from local images folder -- replace and comment out the duplicate\n",
    "dataPath = \"C:/Users/kchan/Desktop/Spring2022/RemoteSensing/Final/FinalRepo/MUSA650_Final_ChangEpstein/data/Images\"\n",
    "#dataPath = \"C:/Users/jenna/Documents/MCP/Spring_2022/MUSA650_RemoteSensing/Final/MUSA650_Final_ChangEpstein/data/Images\"\n",
    "\n",
    "#array of unique labels\n",
    "labelList = os.listdir(dataPath)\n",
    "\n",
    "#read images\n",
    "numClass = len(labelList)\n",
    "\n",
    "lenClass = np.zeros(numClass)\n",
    "for i in np.arange(0, numClass):\n",
    "    lenClass[i] = len(os.listdir(dataPath + '/' + labelList[i]))\n",
    "#returns the number of images in each class\n",
    "lenClass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the total number of images\n",
    "numImg = int(lenClass.sum())\n",
    "numImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting one image\n",
    "import PIL\n",
    "\n",
    "imgSel = dataPath + '/' + labelList[i] + '/' + os.listdir(dataPath + '/' + labelList[i])[29] #this can be any number between 0-165 idk why\n",
    "img = PIL.Image.open(imgSel, 'r')\n",
    "plt.imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(img).shape\n",
    "#200x200 and 3 color channels - does it need to be 224x224?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns total number of pixels per each image\n",
    "numPixels = np.prod(np.asarray(img).shape)\n",
    "numPixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract color channels from each image and flatten to a feature matrix X\n",
    "X = np.zeros([numImg, numPixels])\n",
    "\n",
    "# Create the numeric labels y for each image\n",
    "y = np.zeros(numImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to make it easier to match up text labels with numeric\n",
    "class_dict = dict(zip(labelList, range(len(labelList))))\n",
    "class_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgInd = 0\n",
    "for i in np.arange(0, numClass):\n",
    "  className = labelList[i]\n",
    "  for imgName in os.listdir(dataPath + '/' + className):\n",
    "    img = PIL.Image.open(dataPath + '/' + className + '/' + imgName, 'r')\n",
    "    imgVec = np.asarray(img).flatten()\n",
    "    X[imgInd,:] = imgVec\n",
    "    y[imgInd] = i\n",
    "    imgInd = imgInd + 1\n",
    "    print('Read img class ' + className + ' no ' + str(imgInd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of X before splitting\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of y before splitting\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data, using stratify to ensure even distribution of each classes in each set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5) # Start with 5 neighbors just to get baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model\n",
    "knn_preds = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "accuracy_score(y_test, knn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize parameters -- NOTE: this takes 10 min ito run\n",
    "# Source: https://machinelearningknowledge.ai/knn-classifier-in-sklearn-using-gridsearchcv-with-example/\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Defining range of parameters\n",
    "k_range = list(range(1,31))\n",
    "param_grid_knn = dict(n_neighbors = k_range)\n",
    "\n",
    "#defining grid\n",
    "grid_knn = GridSearchCV(knn_clf, param_grid_knn, cv=10, scoring='accuracy', return_train_score=False, verbose=1)\n",
    "\n",
    "#fitting model for grid search\n",
    "grid_search_knn = grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print best parameters\n",
    "print(grid_search_knn.best_params_)\n",
    "\n",
    "#10 folds for 30 candidates range(1,31) defines 27 neighbors as optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have best params, run again\n",
    "\n",
    "# Defining knn classifier\n",
    "knn_clf_best = KNeighborsClassifier(n_neighbors=27) #using 27 from gridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "knn_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model\n",
    "knn_preds_best = knn_clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "accuracy_score(y_test, knn_preds_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"KNN accuracy score: \",accuracy_score(y_test,knn_preds_best))\n",
    "print(\"KNN classification report \\n\",classification_report(y_test,knn_preds_best))\n",
    "\n",
    "knn_cm = confusion_matrix(y_test,knn_preds_best,  labels = knn_clf_best.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "%matplotlib inline\n",
    "cm = knn_cm.astype('float') / knn_cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# Show all ticks\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       # and label them with the respective list entries\n",
    "       xticklabels=labelList, yticklabels=labelList,\n",
    "       title='KNN Model: Normalized Confusion Matrix',\n",
    "       ylabel='True label',\n",
    "       xlabel='Predicted label')\n",
    "\n",
    "# Loop over data dimensions and create text annotations\n",
    "fmt = '.2f'\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining rf classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(max_depth=10, n_estimators=100, max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model\n",
    "rf_preds = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "accuracy_score(y_test, rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize parameters - should only take <5 min to run currently\n",
    "# Source: https://stackoverflow.com/questions/30102973/how-to-get-best-estimator-on-gridsearchcv-random-forest-classifier-scikit\n",
    "# Defining range of parameters\n",
    "param_grid_rf = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'n_estimators': [200, 700, 900]\n",
    "}\n",
    "\n",
    "#defining grid\n",
    "grid_rf = GridSearchCV(rf_clf, param_grid_rf, cv=10, scoring='accuracy', return_train_score=False, verbose=1)\n",
    "\n",
    "#fitting model for grid search\n",
    "grid_search_rf = grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameters\n",
    "print(grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining rf classifier with best params\n",
    "rf_clf_best = RandomForestClassifier(max_depth=15, n_estimators=700, max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "rf_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model\n",
    "rf_preds_best = rf_clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "accuracy_score(y_test, rf_preds_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RF accuracy score: \",accuracy_score(y_test,rf_preds_best))\n",
    "print(\"RF classification report \\n\",classification_report(y_test,rf_preds_best))\n",
    "\n",
    "rf_cm = confusion_matrix(y_test,rf_preds_best, labels = rf_clf_best.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "%matplotlib inline\n",
    "cm = rf_cm.astype('float') / rf_cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# Show all ticks\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       # and label them with the respective list entries\n",
    "       xticklabels=labelList, yticklabels=labelList,\n",
    "       title='Random Forest Model: Normalized Confusion Matrix',\n",
    "       ylabel='True label',\n",
    "       xlabel='Predicted label')\n",
    "\n",
    "# Loop over data dimensions and create text annotations\n",
    "fmt = '.2f'\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 1st attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in images and retaining rgb\n",
    "import glob\n",
    "import os\n",
    "\n",
    "img_files = []\n",
    "\n",
    "for file in glob.glob(dataPath + os.sep + \"*\" + os.sep + \"*.png\"):\n",
    "    img_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load rgb images\n",
    "imgs_rgb = []\n",
    "\n",
    "for imgName in img_files:\n",
    "    temp = io.imread(imgName)\n",
    "    imgs_rgb.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array\n",
    "RGBimages = np.stack(imgs_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shape\n",
    "RGBimages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(RGBimages,y,test_size=0.5, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale and transform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(X_train.reshape(X_train.shape[0], -1))\n",
    "X_train = scalar.transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
    "X_test = scalar.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set global params\n",
    "batch_size = 64\n",
    "epochs = 12\n",
    "input_shape =(200,200,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = Sequential()\n",
    "\n",
    "cnn1.add(Conv2D(64, kernel_size=(3, 3),strides=(1,1),input_shape=input_shape))\n",
    "cnn1.add(BatchNormalization())\n",
    "cnn1.add(Activation('relu'))\n",
    "cnn1.add(MaxPooling2D((2,2)))\n",
    "\n",
    "cnn1.add(Dropout(0.25))\n",
    "\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dense(numClass, activation='softmax'))\n",
    "\n",
    "cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3b9be1a114b67ae580aea9be56f65615de6f40d02b8026cd32778f2c3fa3664"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('musa-650')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
